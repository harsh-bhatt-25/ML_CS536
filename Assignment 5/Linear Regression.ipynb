{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generating the dataset {-}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def generate(k):\n",
    "    \n",
    "    # Initializing the constants. m here represents the number of features and not the number of datapoints.\n",
    "    m, mu, sigma_sq = 20, 0, 0.1\n",
    "    X, Y = np.zeros([k, m+1]), np.zeros([k,])\n",
    "    \n",
    "    for j in range(k):\n",
    "        x_val, y_val = [], []\n",
    "        \n",
    "        # The first time is the bias\n",
    "        x_val.append(1)\n",
    "        \n",
    "        def generate_x():\n",
    "            for i in range(m):\n",
    "                if i < 11 or i > 15:\n",
    "                    x_val.append(np.random.normal(1, sigma_sq))\n",
    "                elif i == 11:\n",
    "                    x_val.append(x_val[0] + x_val[1] + np.random.normal(mu, sigma_sq))\n",
    "                elif i == 12:\n",
    "                    x_val.append(x_val[2] + x_val[3] + np.random.normal(mu, sigma_sq))\n",
    "                elif i == 13:\n",
    "                    x_val.append(x_val[4] + x_val[5] + np.random.normal(mu, sigma_sq))\n",
    "                elif i == 14:\n",
    "                    x_val.append((0.1 * x_val[6]) + np.random.normal(mu, sigma_sq))\n",
    "                elif i == 15:\n",
    "                    x_val.append((2 * x_val[2]) - 10 + np.random.normal(mu, sigma_sq))\n",
    "            X[j] = np.array(x_val)\n",
    "\n",
    "\n",
    "        def generate_y(x):\n",
    "            for i in range(1, 11):\n",
    "                a = ((0.6 ** i) * x[i]) + np.random.normal(mu, sigma_sq)\n",
    "            Y[j] = 10 + a\n",
    "\n",
    "            \n",
    "        generate_x()\n",
    "        generate_y(x_val)\n",
    "    plt.scatter([p+1 for p in range(k)], Y)\n",
    "    plt.show()\n",
    "    return X, Y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# The parameter passed here is the 'm', i.e., number of datapoints.\n",
    "lr_x, lr_y = generate(1000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Writing a naive Linear Regression class and generating weights {-}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Linear_Regression:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def naive_linear_regression(self, x, y):\n",
    "        # Getting the number of datapoints and number of features.\n",
    "        m, k = x.shape\n",
    "        \n",
    "        # Initializing the weights to be zeros.\n",
    "        self.weights = np.zeros((1, k))\n",
    "        \n",
    "        x_transpose = np.transpose(x)\n",
    "        # Applying the linear regression model to generate weights.\n",
    "        self.weights = np.dot(np.dot(np.linalg.inv(np.dot(x_transpose, x)), x_transpose), y)\n",
    "        return self.weights\n",
    "    \n",
    "    # This function is used to predict using the existing weights.\n",
    "    def predict(self, x, weight):\n",
    "        return np.dot(x, weight)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Training a model and getting the weights.\n",
    "lr = Linear_Regression()\n",
    "lr_weights = lr.naive_linear_regression(lr_x, lr_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plotting the weights {-}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(lr_weights)\n",
    "plt.scatter([i for i in range(21)], lr_weights)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Comparison with \"True weights and biases\" {-}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From our true model, we can see that the true bias value is 10. Also, we can see that the true weights would be $(0.6)^i$. \n",
    "As our bias value is the first term in weights, we can compare it with the true bias."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "true_bias = 10\n",
    "model_bias = lr_weights[0]\n",
    "print(\"The difference between true bias and the bias from the model is {}\".format(true_bias-model_bias))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This says that our bias is a bit larger and the amount by which it is larger is 0.1868."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Most and least significant features {-}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Most significant feature is {}\".format(np.argmax(lr_weights[1:])+1))\n",
    "print(\"Least significant feature is {}\".format(np.argmin(lr_weights[1:])+1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Finding the training error {-}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prediction = lr.predict(x, lr_weights)\n",
    "# Using L2 norm to find the error in the predictions.\n",
    "print(\"Training error is {}%\".format(np.linalg.norm(prediction - y)/1000))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing our model on new data {-}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_x, test_y = generate(1000)\n",
    "predict1 = lr.predict(test_x, weights)\n",
    "print(\"Testing error is {}%\".format(np.linalg.norm(predict1 - test_y)/1000))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Checking if any weights are pruned {-}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "count = 0\n",
    "for check_weight in lr_weights:\n",
    "    if check_weight == 0:\n",
    "        count += 1\n",
    "print(count)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we can see, there is no feature whose weight is 0. As a result, we can say that our algorithm did not prune any weight."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Ridge Regerssion {-}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Ridge_Regression:\n",
    "    def __init__(self, lam):\n",
    "        # Passing the lambda value\n",
    "        self.lam = lam\n",
    "    \n",
    "    def ridge_regression(self, x, y):\n",
    "        # Getting the number of datapoints and number of features.\n",
    "        m, k = x.shape\n",
    "        identity = np.identity(k)\n",
    "        \n",
    "        # Initializing the weights to be zeros.\n",
    "        self.weights = np.zeros((1, k))\n",
    "        \n",
    "        x_transpose = np.transpose(x)\n",
    "        # Applying the linear regression model to generate weights.\n",
    "        self.weights = np.dot(np.dot(np.linalg.inv(np.dot(x_transpose, x) + (self.lam * identity)), x_transpose), y)\n",
    "        return self.weights\n",
    "    \n",
    "    # This function is used to predict using the existing weights.\n",
    "    def predict_ridge(self, x, weight):\n",
    "        return np.dot(x, weight)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Training a model and getting the weights.\n",
    "rr = Ridge_Regression(0.0035)\n",
    "rr_weights = rr.ridge_regression(lr_x, lr_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ridge_prediction = rr.predict_ridge(lr_x, rr_weights)\n",
    "# Using L2 norm to find the error in the predictions.\n",
    "print(\"Training error is {}%\".format(np.linalg.norm(ridge_prediction - lr_y)/1000))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing the Ridge Regression model on a large dataset {-}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_rr_x, test_rr_y = generate(10000)\n",
    "ridge_testing = rr.predict_ridge(test_rr_x, rr_weights)\n",
    "print(\"Testing error for ridge regression is {}%\".format(np.linalg.norm(ridge_testing - test_rr_y)/10000))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plotting against lambda for m = 1000 {-}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lambda_value = -1\n",
    "error_list, m_list = [], []\n",
    "while lambda_value <= 5:\n",
    "    lambda_rr = Ridge_Regression(lambda_value)\n",
    "    lambda_rr_weights = lambda_rr.ridge_regression(lr_x, lr_y)\n",
    "    ridge_pred = rr.predict_ridge(lr_x, lambda_rr_weights)\n",
    "    error = np.linalg.norm(ridge_pred - lr_y)/1000\n",
    "    m_list.append(lambda_value)\n",
    "    error_list.append(error)\n",
    "    lambda_value += 0.1\n",
    "\n",
    "plt.plot(m_list, error_list)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}